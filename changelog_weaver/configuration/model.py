""" This module contains the Model class for the GPT model."""

from dataclasses import dataclass
import logging as log
from typing import List, Dict, Any
import re

# Third party imports
import openai


@dataclass
class Model:
    """
    Configuration class for the GPT model.

    Attributes:
        api_key (str): The API key for the GPT model.
        url (str): The base URL for the GPT model.
        model_name (str): The name of the GPT model.
        model (str): The name of the GPT model.
        models (List[Dict[str, Any]]): A list of available GPT models.
    """

    api_key: str
    url: str
    model_name: str
    model: Dict[str, Any]
    models: List[Dict[str, Any]]

    def __init__(self, key: str, url: str, model_name: str, use_model: bool = True):
        self.client = openai.OpenAI(api_key=key)
        self.api_key = key
        self.url = url
        self.model_name = model_name
        self.use_model = use_model
        self.models = [
            {"Name": "gpt-3.5-turbo", "Tokens": 4096},
            {"Name": "gpt-3.5-turbo-16k", "Tokens": 16385},
            {"Name": "gpt-4", "Tokens": 8192},
            {"Name": "gpt-4-32k", "Tokens": 32768},
            {"Name": "gpt-4o", "Tokens": 128000},
        ]
        self.model = next((m for m in self.models if m["Name"] == self.model_name))
        self.headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}",
        }

    async def summarise(self, prompt: str) -> str:
        """
        Sends a prompt to GPT and returns the response.

        Parameters:
            prompt (str): The input prompt for GPT.

        Returns:
            str: The response generated by GPT.
        """
        token_count = self.count_tokens(prompt)
        if self.model and token_count > self.model["Tokens"]:
            log.warning(
                "The prompt contains too many tokens for the selected model %s/%s. Please reduce the size of the prompt.",
                token_count,
                self.model["Tokens"],
            )
            return ""

        return await self._openai_request(prompt)

    async def _openai_request(self, prompt: str) -> str:
        openai.api_key = self.api_key
        try:
            response = openai.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                stream=False,
                logprobs=False,
            )
            return str(response.choices[0].message.content)
        except openai.APIError as e:
            log.error("OpenAI Error: %s", str(e))
            return f"Error: {str(e)}"

    def count_tokens(self, text: str) -> int:
        """
        Calculates the token count for a given text.

        Parameters:
        text (str): The input text for which the token count needs to be calculated.

        Returns:
        int: The total count of tokens in the given text.
        """
        word_count = len(re.findall(r"\b\w+\b", text))
        char_count = len(re.sub(r"\s", "", text))
        return word_count + char_count
